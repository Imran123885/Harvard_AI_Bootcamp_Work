{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Imran123885/Harvard_AI_Bootcamp_Work/blob/main/imran_mirza_d3c1vc_cnn_student.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLjWPialMbBQ"
      },
      "source": [
        "#Harvard AI Bootcamp - Handwriting Classification with Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make a copy of this notebook! Editing directly will not be saved."
      ],
      "metadata": {
        "id": "rdR8-cp-9aGh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPVZ2bsPMr78"
      },
      "source": [
        "##Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRk_IUlKM3jV"
      },
      "source": [
        "Welcome to this interactive project on Handwriting Classification using Convolutional Neural Networks (CNNs). In this tutorial, we'll explore the powerful capabilities of CNNs in the context of recognizing handwritten digits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYlcmRW2NGm2"
      },
      "source": [
        "##Convolutional Neural Networks (CNNs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve58vdR-NLUJ"
      },
      "source": [
        "Convolutional Neural Networks have emerged as a cornerstone in computer vision, particularly excelling in tasks like image classification. Designed to simulate the visual processing of the human brain, CNNs have proven to be highly effective in discerning intricate patterns and features within images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p55HjK9nNN7O"
      },
      "source": [
        "##Application: Handwriting Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jgFQhj6NUpL"
      },
      "source": [
        "In this project, our focus is on a classic yet vital applicationâ€”recognizing handwritten digits. We'll be working with the MNIST dataset, a benchmark dataset in the machine learning community. Despite its simplicity, MNIST remains a challenging problem due to the wide variability in individual handwriting styles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ink8r0fNW06"
      },
      "source": [
        "##Importance of CNNs in Image Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXdoC-coNZsS"
      },
      "source": [
        "Understanding CNNs is essential in numerous real-world applications, from digit recognition in postal services to automated form processing. By concentrating on the specific task of handwriting classification, we aim to showcase how CNNs can robustly handle diverse and intricate datasets, laying the foundation for broader applications in pattern recognition.\n",
        "\n",
        "Now, let's embark on the journey of setting up our project and constructing a CNN model to proficiently classify handwritten digits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZvQtavHNcXP"
      },
      "source": [
        "#Setup Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGNcFDU1Nobo"
      },
      "source": [
        "In this tutorial, we will be using PyTorch to build a Convolutional Neural Network (CNN) for classifying handwritten digits from the MNIST dataset. Before we dive into the model building process, let's set up our environment by installing the required dependencies and importing the necessary libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Uq-CzswP2ce"
      },
      "source": [
        "##Why PyTorch?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WmpB0YcP5Z9"
      },
      "source": [
        "PyTorch is a popular open-source deep learning framework that provides a flexible and dynamic computational graph. It is widely used for building and training neural networks due to its ease of use, dynamic computation capabilities, and strong community support.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGYNN4wXP9EN"
      },
      "source": [
        "##Step 1: Install Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1sHkKrxP_3X"
      },
      "source": [
        "Let's start by installing the required dependencies. Google Colab comes pre-installed with many essential libraries, but we need to ensure that PyTorch is installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiUUdRsmQCff",
        "outputId": "fb439f2d-a8bd-4651-9fff-304e5cb933af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# Install PyTorch\n",
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK_z58CSQFl0"
      },
      "source": [
        "##Step 2: Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZkMF6nEQLXk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1zQX2uhZ-gc",
        "outputId": "629a4ac7-b115-41d2-e078-5e864dda8cda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C2ygRjhQQwa"
      },
      "source": [
        "\n",
        "\n",
        "*   **'torch'**: The core PyTorch library.\n",
        "*   **'torch.nn'**: PyTorch's module for defining neural network architectures.  \n",
        "*   **'torch.optim'**: PyTorch's module for optimization algorithms.\n",
        "*   **'torchvision'**: PyTorch's library for computer vision tasks.\n",
        "*   **'datasets'**: Provides pre-loaded datasets, including MNIST.\n",
        "*   **'transforms'**: Allows us to define image transformations, such as normalization and resizing.\n",
        "*   **'torch.nn.functional'**: module that provides a collection of functions that operate on tensors and are commonly used in neural network operations. These functions include various activation functions, loss functions, and other operations that are applied element-wise to tensors.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvmihCOQSrNU"
      },
      "source": [
        "##Step 3: Data Preprocessing with Transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANwk2jlSStrL"
      },
      "source": [
        "MNIST dataset contains grayscale images of handwritten digits. We will use transformations to preprocess the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3tX06TPSvd3"
      },
      "outputs": [],
      "source": [
        "# Define data transforms\n",
        "import pandas as pd\n",
        "# TODO: convert images to PyTorch tensors and normalize pixel values to the range [-1, 1]\n",
        "\n",
        "transform = transforms.Compose([\n",
        "      transforms.ToTensor(), # Convert images to pytorch tensors\n",
        "      transforms.Normalize(mean=0.5, std=0.5) # Normalize the tensors to scale them\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNl2X1auTCo_"
      },
      "source": [
        "\n",
        "\n",
        "*   **'ToTensor()'**: Converts images to PyTorch tensors.  \n",
        "*   **'Normalize()'**: Normalizes pixel values to have a mean of 0.5 and a standard deviation of 0.5.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZyj0kycTSbH"
      },
      "source": [
        "##Step 4: Download and Load MNIST Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGsu6Q8mTWMU"
      },
      "source": [
        "Let's download the MNIST dataset and apply the defined transforms:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dvj55zcTYzm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a823da63-f7c5-4fe9-d83d-0e8bf16f8552"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9912422/9912422 [00:00<00:00, 132045490.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28881/28881 [00:00<00:00, 27431090.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1648877/1648877 [00:00<00:00, 55115487.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4542/4542 [00:00<00:00, 10726649.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download and load training set\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "\n",
        "# Download and load test set\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_RwPAlOTlEP"
      },
      "source": [
        "\n",
        "\n",
        "*   **'datasets.MNIST'**: Loads the MNIST dataset.\n",
        "*   **'root'**: Specifies the directory to save the dataset.\n",
        "*   **'train=True'**: Loads the training set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wVaoqcJbH9L",
        "outputId": "8ad67501-72ab-4db7-ae74-48d2d636a1e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: ./data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "               Normalize(mean=0.5, std=0.5)\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y8V1X2JUMWv"
      },
      "source": [
        "##Setup Section Conclusion\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAm9u-stUPe7"
      },
      "source": [
        "With these setup steps, we have created an environment ready for building our CNN for handwritten digit classification using PyTorch. In the upcoming sections, we will delve into constructing the neural network architecture, training the model, and evaluating its performance.\n",
        "\n",
        "Let's proceed to the next section and start building our CNN!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRSvQvfPU0gW"
      },
      "source": [
        "#Building the CNN Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VTLTtlCU3Am"
      },
      "source": [
        "Now that we have set up our environment and loaded the MNIST dataset, let's move on to building the Convolutional Neural Network (CNN) for classifying handwritten digits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpP0m3liUuW-"
      },
      "source": [
        "##Step 5: Define the CNN Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMwKloG4U56P"
      },
      "source": [
        "We will create a simple CNN architecture for this task. In this example, we'll use two convolutional layers followed by max-pooling, and then two fully connected (linear) layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgXCmqGGU8Qb"
      },
      "outputs": [],
      "source": [
        "class CNNClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNClassifier, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        # TODO: similarly create another convolutional layer\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1) # Output of precvious layer is 32, input for next layer is 64\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        # TODO: similarly create another fully connected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBKIWBKKU-2V"
      },
      "source": [
        "This architecture consists of two convolutional layers, each followed by max-pooling, and two fully connected layers. The forward method defines the forward pass of the network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bB8rOLqzVCj1"
      },
      "source": [
        "##Step 6: Instantiate the Model and Define Loss Function & Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdJmEpeRVFvz"
      },
      "source": [
        "Now, let's instantiate the CNN model and define the loss ffunction and optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkiZCQXtVJb5"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model\n",
        "model = CNNClassifier()\n",
        "\n",
        "# Define Cross Entropy loss function\n",
        "# TODO: Define an Adam optimizer and specify the learning rate\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr= 0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGbud00lVLsr"
      },
      "source": [
        "\n",
        "\n",
        "*   **'nn.CrossEntropyLoss()'**: This is a commonly used loss function for classification problems.\n",
        "*   **'optim.Adam()'**: We use the Adam optimizer for updating the model parameters during training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkS62Ge0VYOl"
      },
      "source": [
        "##Step 7: Training the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_0h7CbhVaSr"
      },
      "source": [
        "Let's train the model using the training dataset we loaded earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kgUFvTPVc5V",
        "outputId": "fdef1f86-cba5-4449-e33c-e48c2eb6b7d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.1619, Accuracy: 95.05%\n",
            "Epoch [2/5], Loss: 0.0463, Accuracy: 98.58%\n",
            "Epoch [3/5], Loss: 0.0325, Accuracy: 98.99%\n",
            "Epoch [4/5], Loss: 0.0237, Accuracy: 99.25%\n",
            "Epoch [5/5], Loss: 0.0193, Accuracy: 99.38%\n"
          ]
        }
      ],
      "source": [
        "# Defne batch size for tarining\n",
        "batch_size = 64\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Set the number of epochs\n",
        "num_epochs = 5\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # TODO: set the model to training model\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train, total_train = 0, 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        # TODO: Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "        # TODO: Forward pass\n",
        "        outputs = model(images)\n",
        "        # TODO: Calculate the loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        # TODO: Backward pass\n",
        "        loss.backward()\n",
        "        # TODO: Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    accuracy_train = correct_train / total_train\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy_train * 100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5moPWBzvVeln"
      },
      "source": [
        "*   **'optimizer.zero_grad()'**: Clears the gradients of all optimized tensors.\n",
        "*   **'outputs = model(images)'**: Performs a forward pass to obtain model predictions.\n",
        "*   **criterion(outputs, labels)'**: Computes the loss between the predicted and true labels.\n",
        "*   **'loss.backward()'**: Computes the gradients with respect to the loss.\n",
        "*   **'optimizer.step()'**: Updates the model parameters based on the computed gradients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iF8XYHm9WBRO"
      },
      "source": [
        "##Step 8: Evaluate the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLttrIBQWDdB"
      },
      "source": [
        "After training, let's evaluate the model on the test set to assess it's performance. One popular visualzation of a model's performance is a confusion matrix. To do this, we'll need to use the **'sklearn.metrics'** module, which provides convenient functions for calculating and displaying various metrics.\n",
        "\n",
        "First make sure to install scikit-learn if you haven't already:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYvDcNtbbO-2",
        "outputId": "986897ab-0240-47a3-a55f-f1f2fbf09d68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-U-x2YabQ9N"
      },
      "source": [
        "Now let's modify the import statements to include the calculation and printing of the confusion matrix and classificaiton report:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLlSld5sbUuh"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WBzhab7WHct",
        "outputId": "d3005f5c-8e37-4365-8850-10cc49d9cf87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 99.27%\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 974    0    0    1    0    1    1    2    1    0]\n",
            " [   0 1133    1    0    0    0    0    1    0    0]\n",
            " [   0    3 1019    1    1    0    1    5    2    0]\n",
            " [   0    0    0 1005    0    4    0    0    1    0]\n",
            " [   0    0    0    0  977    0    0    0    0    5]\n",
            " [   0    0    0    2    0  888    2    0    0    0]\n",
            " [   2    2    0    0    1    1  950    0    2    0]\n",
            " [   0    1    2    0    0    0    0 1019    1    5]\n",
            " [   1    0    1    2    0    0    0    0  968    2]\n",
            " [   0    0    0    0    6    3    0    4    2  994]]\n"
          ]
        }
      ],
      "source": [
        "# Evaluation on the test set\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "correct_test, total_test = 0, 0\n",
        "all_predicted, all_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_test += labels.size(0)\n",
        "        correct_test += (predicted == labels).sum().item()\n",
        "\n",
        "        # Collect predictions and true labels for later analysis\n",
        "        all_predicted.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "# TODO: calculate accuracy_test\n",
        "accuracy_test = correct_test/total_test\n",
        "\n",
        "# Print test accuracy\n",
        "print(f'Test Accuracy: {accuracy_test * 100:.2f}%')\n",
        "\n",
        "# Calculate and print confusion matrix\n",
        "conf_matrix = confusion_matrix(all_labels, all_predicted)\n",
        "print('\\nConfusion Matrix:')\n",
        "print(conf_matrix)\n",
        "\n",
        "# Calculate and print classification report\n",
        "class_report = classification_report(all_labels, all_predicted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6JPsSYaWJHe"
      },
      "source": [
        "This code snippet sets the model to evaluation mode, runs the test data through the trained model, and calculates the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "-WR-7m2FjCq7",
        "outputId": "e182f823-abf6-46ff-d31e-73659a801b96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'              precision    recall  f1-score   support\\n\\n           0       1.00      0.99      1.00       980\\n           1       0.99      1.00      1.00      1135\\n           2       1.00      0.99      0.99      1032\\n           3       0.99      1.00      0.99      1010\\n           4       0.99      0.99      0.99       982\\n           5       0.99      1.00      0.99       892\\n           6       1.00      0.99      0.99       958\\n           7       0.99      0.99      0.99      1028\\n           8       0.99      0.99      0.99       974\\n           9       0.99      0.99      0.99      1009\\n\\n    accuracy                           0.99     10000\\n   macro avg       0.99      0.99      0.99     10000\\nweighted avg       0.99      0.99      0.99     10000\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xxlesHAWvXx"
      },
      "source": [
        "##Step 9: Visualize the Results of our Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "4ch-vsRlY_3p",
        "outputId": "c64fe64d-7a15-421f-b311-f2736c205db3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.0146\n",
            "Epoch [2/5], Loss: 0.0114\n",
            "Epoch [3/5], Loss: 0.0092\n",
            "Epoch [4/5], Loss: 0.0088\n",
            "Epoch [5/5], Loss: 0.0064\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Function to visualize test images and predictions\n",
        "def visualize_results(model, test_loader, num_images=5):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (images, labels) in enumerate(test_loader):\n",
        "            if i >= num_images:\n",
        "                break\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            # Convert the image tensor to a NumPy array\n",
        "            image = images[0][0].squeeze().cpu().numpy()\n",
        "\n",
        "            # Visualize the test images and their predictions\n",
        "            plt.subplot(1, num_images, i + 1)\n",
        "            plt.imshow(image, cmap='gray')  # Use the NumPy array for imshow\n",
        "            plt.title(f'Predicted: {predicted[0]}\\nActual: {labels[0]}')\n",
        "            plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Visualize test images and predictions\n",
        "visualize_results(model, test_loader)\n",
        "\n",
        "# Function to plot the training loss over epochs\n",
        "def plot_loss(loss_values):\n",
        "    plt.plot(loss_values, label='Training Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Loss Over Epochs')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Training loop with loss tracking\n",
        "loss_values = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    loss_values.append(epoch_loss)\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
        "\n",
        "# Visualize the training loss over epochs\n",
        "plot_loss(loss_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqy-bLAPZBva"
      },
      "source": [
        "*   **'visualize_results'**: This function takes the trained model and a test data loader as input and visualizes a specified number of test images along with their predicted and actual labels.\n",
        "*   **'plot_loss'**: This function takes a list of training loss values over epochs and plots a graph to visualize the training loss trend."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkT3AlTweA5F"
      },
      "source": [
        "#Let's Upgrade Our CNN!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKE_C_k5eHS1"
      },
      "source": [
        "There are several next steps we can take to bring our current CNN to the next level. Two of the most common next steps are updating the CNN architecture and data augmentation. We will be implementing both in the next few steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef9i99_DeWYK"
      },
      "source": [
        "##Step 10: Update CNN Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4o4Zbp3XecOO"
      },
      "outputs": [],
      "source": [
        "# Define the advanced CNN architecture\n",
        "class AdvancedCNNClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AdvancedCNNClassifier, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Calculate the size dynamically based on the input size to the linear layer\n",
        "        dummy_input = torch.randn(1, 1, 28, 28)\n",
        "        self.calculate_conv_output_size(dummy_input)\n",
        "\n",
        "        self.fc1 = nn.Linear(self.conv_output_size, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "    def calculate_conv_output_size(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        self.conv_output_size = x.size(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIJmeK-cef5a"
      },
      "source": [
        "We've defined a new CNN architcture named **'AdvancedCNNClassifier'** with three convolutional layers('conv1', 'conv2', 'conv3'), max-pooling layers('pool'), and wo fully connected layers ('fc1', 'fc2').\n",
        "\n",
        "\n",
        "The architecture is more complex than the previous CNN, with additional convolutional and fully connected layers.\n",
        "\n",
        "\n",
        "In this step we've also introduced a method 'calculate_conv_output_size' that takes. adummy input and calculates the size after the last pooling layer. This size is then used to dynamically set the input size of the first linear layer('fc1'). Please try this modification and see if it resolves the issue."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afPDNpvihc66"
      },
      "source": [
        "To provide some general foundational reasoning for updates in CNN architecture:\n",
        "\n",
        "1. Increased Model Capacity: The original CNN architecture might not have enough capacity to capture intricate patterns in the data. By introducing more convolutional layers and parameters, the model becomes more expressive and can potentially learn more complex features.\n",
        "2. Hierarchical Feature Extraction: Deepening the architecture allows the network to perform hierarchical feature extraction. Each layer can learn and represent different levels of abstraction, enabling the model to understand more intricate structures in the input data.\n",
        "3. Representation Power: The deeper architecture provides the model with a higher capacity to represent both low-level and high-level features in the data. This can be particularly beneficial for image classification tasks where features are hierarchical."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUgKYOOZe2z0"
      },
      "source": [
        "##Step 11: Data Augmentaiton\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9hguoOZe58k"
      },
      "outputs": [],
      "source": [
        "# Define data transforms for training with data augmentation\n",
        "transform_with_augmentation = transforms.Compose([\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomResizedCrop(28, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Download and load the training set with data augmentation\n",
        "train_dataset_with_augmentation = datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    transform=transform_with_augmentation,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "# Create a data loader for the augmented training set\n",
        "train_loader_with_augmentation = torch.utils.data.DataLoader(\n",
        "    dataset=train_dataset_with_augmentation,\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PjTyKUdfJNL"
      },
      "source": [
        "We've defined a new set of data transformation('transform_with_augmentation') for training with data augmentation.\n",
        "\n",
        "The transformations include random rotation, random resized crop, and random horizontal flip, augmenting the training images.\n",
        "\n",
        "We've created a new training dataste('train_dataset_with_augmentation') with the specified augmentations.\n",
        "\n",
        "Finally, a new data loader ('train_loader_with_augmentation') is created for the augmented training dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQ8VPCc_iCWL"
      },
      "source": [
        "To provide some foundational reasoning for why one might want to perform data augmentation:\n",
        "1. Increased Robustness: Data augmentation introduces diversity into the training set by applying random transformations to the images. This helps the model become more robust and less sensitive to variations in the input data.\n",
        "2. Improved Generalization: Augmenting the training data with variations like rotation, scaling, and flipping exposes the model to a broader range of scenarios. This aids in improving the model's ability to generalize well to unseen data.\n",
        "3. Mitigation of Overfitting: Data augmentation acts as a form of regularization by artificially expanding the dataset. This can be particularly helpful in mitigating overfitting, where the model memorizes the training set instead of learning generalizable patterns.\n",
        "4. Realistic Input Variations: By simulating realistic variations that the model might encounter in real-world scenarios, data augmentation helps the model become more adaptive and capable of handling diverse inputs.\n",
        "5. Reudced Dependency on Large Datasets: In scenarios where collecting a large labeled dataset is challenging, data augmentation provides a way to artificially increase the effective size of the training set. This is especially useful for small to moderately sized datasets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQLZ69CUfz_c"
      },
      "source": [
        "## Step 12: Run Training Loop Again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqY21Ppff3ia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "405990b9-7786-4091-ae1a-c08429949465"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.3529, Accuracy: 88.53\n",
            "Epoch [2/5], Loss: 0.1185, Accuracy: 96.31\n",
            "Epoch [3/5], Loss: 0.0915, Accuracy: 97.12\n",
            "Epoch [4/5], Loss: 0.0806, Accuracy: 97.49\n",
            "Epoch [5/5], Loss: 0.0726, Accuracy: 97.71\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the advanced CNN model\n",
        "advanced_model = AdvancedCNNClassifier()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(advanced_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop with data augmentation\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    advanced_model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train, total_train = 0, 0\n",
        "\n",
        "    for images, labels in train_loader_with_augmentation:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = advanced_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader_with_augmentation)\n",
        "    accuracy_train = correct_train / total_train\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy_train * 100:.2f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtlSpaZwgz3a"
      },
      "source": [
        "We've instnatiated the advanced CNN model ('AdvancedCNNClassifier'). The loss function is defined as cross-entropy, and the optimizer is set to Adam witha learning rate of 0.001\n",
        "\n",
        "The training loop is similar to the augmented training dataset ('train_loader_with_augmentation). The loop then prints the training loss and accuracy for each epoch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OLz6SS0ioIw"
      },
      "source": [
        "Incorporating both an advanced architecture and data augmentation aligns with the goal of building a more powerful and robust model, capable of accurately classifying handwritten digits while being less sensitive to variations and noise in the input data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITQrcByYWPpM"
      },
      "source": [
        "#Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMoZ5lxoWVRj"
      },
      "source": [
        "Congratulations! You've successfully built and trained a Convolutional Neural Network for classifying handwritten digits using PyTorch. In this tutorial, we covered setting up the environment, defining the CNN architecture, training the model, and evaluating its performance.\n",
        "\n",
        "Feel free to experiment with different architectures, hyperparameters, and techniques to further improve the model's accuracy."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}